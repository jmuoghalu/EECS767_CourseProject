parallel comput wikipedia parallel comput wikipedia free encyclopedia jump navig search ibm blue genep massiv parallel supercomput parallel comput type comput mani calcul execut process carri concurr 1 larg problem often divid smaller one solv time sever differ form parallel comput bitlevel instructionlevel data task parallel parallel long employ highperform comput gain broader interest due physic constraint prevent frequenc scale 2 power consumpt consequ heat gener comput becom concern recent year 3 parallel comput becom domin paradigm comput architectur mainli form multicor processor 4 parallel comput close relat concurr comput frequent use togeth often conflat though two distinct possibl parallel without concurr bitlevel parallel concurr without parallel multitask timeshar singlecor cpu 5 6 parallel comput comput task typic broken sever often mani similar subtask process independ whose result combin afterward upon complet contrast concurr comput variou process often address relat task typic distribut comput separ task may vari natur often requir interprocess commun execut parallel comput roughli classifi accord level hardwar support parallel multicor multiprocessor comput multipl process element within singl machin cluster mpp grid use multipl comput work task special parallel comput architectur sometim use alongsid tradit processor acceler specif task case parallel transpar programm bitlevel instructionlevel parallel explicitli parallel algorithm particularli use concurr difficult write sequenti one 7 concurr introduc sever new class potenti softwar bug race condit common commun synchron differ subtask typic greatest obstacl get good parallel program perform theoret upper bound speedup singl program result parallel given amdahl law content edit tradit comput softwar written serial comput solv problem algorithm construct implement serial stream instruct instruct execut central process unit one comput one instruct may execut timeaft instruct finish next one execut 8 parallel comput hand use multipl process element concurr solv problem accomplish break problem independ part process element execut part algorithm concurr other process element divers includ resourc singl comput multipl processor sever network comput special hardwar combin 8 histor parallel comput use scientif comput simul scientif problem particularli natur engin scienc meteorolog led design parallel hardwar softwar well high perform comput 9 frequenc scale domin reason improv comput perform mid1980 2004 runtim program equal number instruct multipli averag time per instruct maintain everyth els constant increas clock frequenc decreas averag time take execut instruct increas frequenc thu decreas runtim computebound program 10 howev power consumpt p chip given equat p c v 2 f c capacit switch per clock cycl proport number transistor whose input chang v voltag f processor frequenc cycl per second 11 increas frequenc increas amount power use processor increas processor power consumpt led ultim intel may 8 2004 cancel teja jayhawk processor gener cite end frequenc scale domin comput architectur paradigm 12 deal problem power consumpt overh major central process unit cpu processor manufactur start produc power effici processor multipl core core comput unit processor multicor processor core independ access memori concurr multicor processor brought parallel comput desktop comput thu parallelis serial programm becom mainstream program task 2012 quadcor processor becam standard desktop comput server 10 12 core processor moor law predict number core per processor doubl everi 1824 month could mean 2020 typic processor dozen hundr core 13 oper system ensur differ task user programm run parallel avail core howev serial softwar programm take full advantag multicor architectur programm need restructur parallelis code speedup applic softwar runtim longer achiev frequenc scale instead programm need parallelis softwar code take advantag increas comput power multicor architectur 14 edit graphic represent amdahl law speedup program parallel limit much program parallel exampl 90 program parallel theoret maximum speedup use parallel comput would 10 time matter mani processor use assum task two independ part b part b take roughli 25 time whole comput work hard one may abl make part 5 time faster reduc time whole comput littl contrast one may need perform less work make part twice fast make comput much faster optim part b even though part b speedup greater ratio 5 time versu 2 time optim speedup parallel would lineardoubl number process element halv runtim doubl second time halv runtim howev parallel algorithm achiev optim speedup nearlinear speedup small number process element flatten constant valu larg number process element potenti speedup algorithm parallel comput platform given amdahl law 15 latenc potenti speedup latenc execut whole task speedup latenc execut paralleliz part task p percentag execut time whole task concern paralleliz part task parallel sinc show small part program cannot parallel limit overal speedup avail parallel program solv larg mathemat engin problem typic consist sever paralleliz part sever nonparalleliz serial part nonparalleliz part program account 10 runtim p 09 get 10 time speedup regardless mani processor ad put upper limit use ad parallel execut unit task cannot partit sequenti constraint applic effort effect schedul bear child take nine month matter mani women assign 16 graphic represent gustafson law amdahl law appli case problem size fix practic comput resourc becom avail tend get use larger problem larger dataset time spent paralleliz part often grow much faster inher serial work 17 case gustafson law give less pessimist realist assess parallel perform 18 amdahl law gustafson law assum run time serial part program independ number processor amdahl law assum entir problem fix size total amount work done parallel also independ number processor wherea gustafson law assum total amount work done parallel vari linearli number processor edit understand data depend fundament implement parallel algorithm program run quickli longest chain depend calcul known critic path sinc calcul depend upon prior calcul chain must execut order howev algorithm consist long chain depend calcul usual opportun execut independ calcul parallel let p p j two program segment bernstein condit 19 describ two independ execut parallel p let input variabl output variabl likewis p j p p j independ satisfi violat first condit introduc flow depend correspond first segment produc result use second segment second condit repres antidepend second segment produc variabl need first segment third final condit repres output depend two segment write locat result come logic last execut segment 20 consid follow function demonstr sever kind depend 1 function depa b 2 c b 3 3 c 4 end function exampl instruct 3 cannot execut even parallel instruct 2 instruct 3 use result instruct 2 violat condit 1 thu introduc flow depend 1 function nodepa b 2 c b 3 3 b 4 e b 5 end function exampl depend instruct run parallel bernstein condit allow memori share differ process mean enforc order access necessari semaphor barrier synchron method edit subtask parallel program often call thread parallel comput architectur use smaller lightweight version thread known fiber other use bigger version known process howev thread gener accept gener term subtask thread often need updat variabl share instruct two program may interleav order exampl consid follow program thread thread b 1a read variabl v 1b read variabl v 2a add 1 variabl v 2b add 1 variabl v 3a write back variabl v 3b write back variabl v instruct 1b execut 1a 3a instruct 1a execut 1b 3b program produc incorrect data known race condit programm must use lock provid mutual exclus lock program languag construct allow one thread take control variabl prevent thread read write variabl unlock thread hold lock free execut critic section section program requir exclus access variabl unlock data finish therefor guarante correct program execut program rewritten use lock thread thread b 1a lock variabl v 1b lock variabl v 2a read variabl v 2b read variabl v 3a add 1 variabl v 3b add 1 variabl v 4a write back variabl v 4b write back variabl v 5a unlock variabl v 5b unlock variabl v one thread success lock variabl v thread lock unabl proceed v unlock guarante correct execut program lock necessari ensur correct program execut greatli slow program lock multipl variabl use nonatom lock introduc possibl program deadlock atom lock lock multipl variabl cannot lock lock two thread need lock two variabl use nonatom lock possibl one thread lock one second thread lock second variabl case neither thread complet deadlock result mani parallel program requir subtask act synchroni requir use barrier barrier typic implement use softwar lock one class algorithm known lockfre waitfre algorithm altogeth avoid use lock barrier howev approach gener difficult implement requir correctli design data structur parallel result speedup gener task split thread thread spend everincreas portion time commun eventu overhead commun domin time spent solv problem parallel split workload even thread increas rather decreas amount time requir finish known parallel slowdown 21 edit applic often classifi accord often subtask need synchron commun applic exhibit finegrain parallel subtask must commun mani time per second exhibit coarsegrain parallel commun mani time per second exhibit embarrass parallel rare never commun embarrassingli parallel applic consid easiest parallel edit main articl consist model parallel program languag parallel comput must consist model also known memori model consist model defin rule oper comput memori occur result produc one first consist model lesli lamport sequenti consist model sequenti consist properti parallel program parallel execut produc result sequenti program specif program sequenti consist result execut oper processor execut sequenti order oper individu processor appear sequenc order specifi program 22 softwar transact memori common type consist model softwar transact memori borrow databas theori concept atom transact appli memori access mathemat model repres sever way introduc 1962 petri net earli attempt codifi rule consist model dataflow theori later built upon dataflow architectur creat physic implement idea dataflow theori begin late 1970 process calculi calculu commun system commun sequenti process develop permit algebra reason system compos interact compon recent addit process calculu famili calculu ad capabl reason dynam topolog logic lamport tla mathemat model trace actor event diagram also develop describ behavior concurr system see also relax sequenti edit michael j flynn creat one earliest classif system parallel sequenti comput program known flynn taxonomi flynn classifi program comput whether oper use singl set multipl set instruct whether instruct use singl set multipl set data flynn taxonomi singl data stream sisd misd multipl data stream simd mimd spmd mpmd singleinstructionsingledata sisd classif equival entir sequenti program singleinstructionmultipledata simd classif analog oper repeatedli larg data set commonli done signal process applic multipleinstructionsingledata misd rare use classif comput architectur deal devis systol array applic fit class materi multipleinstructionmultipledata mimd program far common type parallel program accord david patterson john l hennessi machin hybrid categori cours classic model surviv simpl easi understand give good first approxim alsoperhap understandabilityth wide use scheme 23 edit edit main articl bitlevel parallel advent verylargescal integr vlsi computerchip fabric technolog 1970 1986 speedup comput architectur driven doubl comput word size amount inform processor manipul per cycl 24 increas word size reduc number instruct processor must execut perform oper variabl whose size greater length word exampl 8bit processor must add two 16bit integ processor must first add 8lowerord bit integ use standard addit instruct add 8higherord bit use addwithcarri instruct carri bit lower order addit thu 8bit processor requir two instruct complet singl oper 16bit processor would abl complet oper singl instruct histor 4bit microprocessor replac 8bit 16bit 32bit microprocessor trend gener came end introduct 32bit processor standard generalpurpos comput two decad earli 2000 advent x8664 architectur 64bit processor becom commonplac edit main articl instructionlevel parallel canon processor without pipelin take five clock cycl complet one instruct thu processor issu subscalar perform canon fivestag pipelin processor best case scenario take one clock cycl complet one instruct thu processor issu scalar perform comput program essenc stream instruct execut processor without instructionlevel parallel processor issu less one instruct per clock cycl processor known subscalar processor instruct reorder combin group execut parallel without chang result program known instructionlevel parallel advanc instructionlevel parallel domin comput architectur mid1980 mid1990 25 modern processor multistag instruct pipelin stage pipelin correspond differ action processor perform instruct stage processor n stage pipelin n differ instruct differ stage complet thu issu one instruct per clock cycl processor known scalar processor canon exampl pipelin processor risc processor five stage instruct fetch instruct decod id execut ex memori access mem regist write back wb pentium 4 processor 35stage pipelin 26 canon fivestag pipelin superscalar processor best case scenario take one clock cycl complet two instruct thu processor issu superscalar perform modern processor also multipl execut unit usual combin featur pipelin thu issu one instruct per clock cycl processor known superscalar processor instruct group togeth data depend scoreboard tomasulo algorithm similar scoreboard make use regist renam two common techniqu implement outoford execut instructionlevel parallel edit main articl task parallel task parallel characterist parallel program entir differ calcul perform either differ set data 27 contrast data parallel calcul perform differ set data task parallel involv decomposit task subtask alloc subtask processor execut processor would execut subtask concurr often cooper task parallel usual scale size problem 28 edit edit main memori parallel comput either share memori share process element singl address space distribut memori process element local address space 29 distribut memori refer fact memori logic distribut often impli physic distribut well distribut share memori memori virtual combin two approach process element local memori access memori nonloc processor access local memori typic faster access nonloc memori logic view nonuniform memori access numa architectur processor one directori access directori memori less latenc access memori directori memori comput architectur element main memori access equal latenc bandwidth known uniform memori access uma system typic achiev share memori system memori physic distribut system properti known nonuniform memori access numa architectur distribut memori system nonuniform memori access comput system make use cach small fast memori locat close processor store temporari copi memori valu nearbi physic logic sens parallel comput system difficulti cach may store valu one locat possibl incorrect program execut comput requir cach coher system keep track cach valu strateg purg thu ensur correct program execut bu snoop one common method keep track valu access thu purg design larg highperform cach coher system difficult problem comput architectur result share memori comput architectur scale well distribut memori system 29 processorprocessor processormemori commun implement hardwar sever way includ via share either multiport multiplex memori crossbar switch share bu interconnect network myriad topolog includ star ring tree hypercub fat hypercub hypercub one processor node ndimension mesh parallel comput base interconnect network need kind rout enabl pass messag node directli connect medium use commun processor like hierarch larg multiprocessor machin edit parallel comput roughli classifi accord level hardwar support parallel classif broadli analog distanc basic comput node mutual exclus exampl cluster symmetr multiprocessor rel common edit main articl multicor processor multicor processor processor includ multipl process unit call core chip processor differ superscalar processor includ multipl execut unit issu multipl instruct per clock cycl one instruct stream thread contrast multicor processor issu multipl instruct per clock cycl multipl instruct stream ibm cell microprocessor design use soni playstat 3 promin multicor processor core multicor processor potenti superscalar wellthat everi clock cycl core issu multipl instruct one thread concurr multithread intel hyperthread best known earli form pseudomulticor processor capabl concurr multithread includ multipl execut unit process unitthat superscalar architectureand issu multipl instruct per clock cycl multipl thread tempor multithread hand includ singl execut unit process unit issu one instruct time multipl thread edit main articl symmetr multiprocess symmetr multiprocessor smp comput system multipl ident processor share memori connect via bu 30 bu content prevent bu architectur scale result smp gener compris 32processor 31 small size processor signific reduct requir bu bandwidth achiev larg cach symmetr multiprocessor extrem costeffect provid suffici amount memori bandwidth exist 30 edit main articl distribut comput distribut comput also known distribut memori multiprocessor distribut memori comput system process element connect network distribut comput highli scalabl term concurr comput parallel comput distribut comput lot overlap clear distinct exist 32 system may character parallel distribut processor typic distribut system run concurr parallel 33 edit main articl comput cluster beowulf cluster cluster group loos coupl comput work togeth close respect regard singl comput 34 cluster compos multipl standalon machin connect network machin cluster symmetr load balanc difficult common type cluster beowulf cluster cluster implement multipl ident commerci offtheshelf comput connect tcpip ethernet local area network 35 beowulf technolog origin develop thoma sterl donald becker vast major top500 supercomput cluster 36 grid comput system describ easili handl embarrassingli parallel problem modern cluster typic design handl difficult problemsproblem requir node share intermedi result often requir high bandwidth importantli low latenc interconnect network mani histor current supercomput use custom highperform network hardwar specif design cluster comput cray gemini network 37 2014 current supercomput use offtheshelf standard network hardwar often myrinet infiniband gigabit ethernet edit main articl massiv parallel comput cabinet ibm blue genel massiv parallel supercomput massiv parallel processor mpp singl comput mani network processor mpp mani characterist cluster mpp special interconnect network wherea cluster use commod hardwar network mpp also tend larger cluster typic far 100processor 38 mpp cpu contain memori copi oper system applic subsystem commun other via highspe interconnect 39 ibm blue genel fifth fastest supercomput world accord june 2009 top500 rank mpp edit main articl grid comput grid comput distribut form parallel comput make use comput commun internet work given problem low bandwidth extrem high latenc avail internet distribut comput typic deal embarrassingli parallel problem mani distribut comput applic creat setihom foldinghom bestknown exampl 40 grid comput applic use middlewar softwar sit oper system applic manag network resourc standard softwar interfac common distribut comput middlewar berkeley open infrastructur network comput boinc often distribut comput softwar make use spare cycl perform comput time comput idl edit within parallel comput special parallel devic remain nich area interest domainspecif tend applic class parallel problem edit reconfigur comput use fieldprogramm gate array fpga coprocessor generalpurpos comput fpga essenc comput chip rewir given task fpga program hardwar descript languag vhdl verilog howev program languag tediou sever vendor creat c hdl languag attempt emul syntax semant c program languag programm familiar best known c hdl languag mitrionc impuls c dimec handelc specif subset systemc base c also use purpos amd decis open hypertransport technolog thirdparti vendor becom enabl technolog highperform reconfigur comput 41 accord michael r damour chief oper offic drc comput corpor first walk amd call us socket stealer call us partner 41 edit main articl gpgpu nvidia tesla gpgpu card generalpurpos comput graphic process unit gpgpu fairli recent trend comput engin research gpu coprocessor heavili optim comput graphic process 42 comput graphic process field domin data parallel operationsparticularli linear algebra matrix oper earli day gpgpu program use normal graphic api execut program howev sever new program languag platform built gener purpos comput gpu nvidia amd releas program environ cuda stream sdk respect gpu program languag includ brookgpu peakstream rapidmind nvidia also releas specif product comput tesla seri technolog consortium khrono group releas opencl specif framework write program execut across platform consist cpu gpu amd appl intel nvidia other support opencl edit main articl applicationspecif integr circuit sever applicationspecif integr circuit asic approach devis deal parallel applic 43 44 45 asic definit specif given applic fulli optim applic result given applic asic tend outperform generalpurpos comput howev asic creat uv photolithographi process requir mask set extrem expens mask set cost million us dollar 46 smaller transistor requir chip expens mask meanwhil perform increas generalpurpos comput time describ moor law tend wipe gain one two chip gener 41 high initi cost tendenc overtaken mooreslawdriven generalpurpos comput render asic unfeas parallel comput applic howev built one exampl pflop riken mdgrape3 machin use custom asic molecular dynam simul edit main articl vector processor cray1 vector processor vector processor cpu comput system execut instruct larg set data vector processor highlevel oper work linear array number vector exampl vector oper b c b c 64element vector 64bit floatingpoint number 47 close relat flynn simd classif 47 cray comput becam famou vectorprocess comput 1970 1980 howev vector processorsboth cpu full comput systemshav gener disappear modern processor instruct set includ vector process instruct freescal semiconductor altivec intel stream simd extens sse edit edit main articl list concurr parallel program languag concurr program languag librari api parallel program model algorithm skeleton creat program parallel comput gener divid class base assumpt make underli memori architectureshar memori distribut memori share distribut memori share memori program languag commun manipul share memori variabl distribut memori use messag pass posix thread openmp two wide use share memori api wherea messag pass interfac mpi wide use messagepass system api 48 one concept use program parallel program futur concept one part program promis deliv requir datum anoth part program futur time cap entrepris pathscal also coordin effort make hybrid multicor parallel program hmpp direct open standard call openhmpp openhmpp directivebas program model offer syntax effici offload comput hardwar acceler optim data movement tofrom hardwar memori openhmpp direct describ remot procedur call rpc acceler devic eg gpu gener set core direct annot c fortran code describ two set function offload procedur denot codelet onto remot devic optim data transfer cpu main memori acceler memori rise consum gpu led support comput kernel either graphic api refer comput shader dedic api opencl languag extens edit main articl automat parallel automat parallel sequenti program compil holi grail parallel comput despit decad work compil research automat parallel limit success 49 mainstream parallel program languag remain either explicitli parallel best partial implicit programm give compil direct parallel fulli implicit parallel program languag exist sisal parallel haskel sequencel system c fpga mitrionc vhdl verilog edit main articl applic checkpoint comput system grow complex mean time failur usual decreas applic checkpoint techniqu wherebi comput system take snapshot applicationa record current resourc alloc variabl state akin core dump inform use restor program comput fail applic checkpoint mean program restart last checkpoint rather begin checkpoint provid benefit varieti situat especi use highli parallel system larg number processor use high perform comput 50 edit parallel comput becom larger faster abl solv problem previous taken long run field vari bioinformat protein fold sequenc analysi econom mathemat financ taken advantag parallel comput common type problem parallel comput applic includ 51 dens linear algebra spars linear algebra spectral method cooleytukey fast fourier transform n bodi problem barneshut simul structur grid problem lattic boltzmann method unstructur grid problem found finit element analysi mont carlo method combin logic bruteforc cryptograph techniqu graph travers sort algorithm dynam program branch bound method graphic model detect hidden markov model construct bayesian network finitest machin simul edit inform faulttoler comput system parallel comput also appli design faulttoler comput system particularli via lockstep system perform oper parallel provid redund case one compon fail also allow automat error detect error correct result differ method use help prevent singleev upset caus transient error 52 although addit measur may requir embed special system method provid cost effect approach achiev nmodular redund commerci offtheshelf system edit main articl histori comput illiac iv infam supercomput 53 origin true mimd parallel go back luigi federico menabrea sketch analyt engin invent charl babbag 54 55 56 april 1958 gill ferranti discuss parallel program need branch wait 57 also 1958 ibm research john cock daniel slotnick discuss use parallel numer calcul first time 58 burrough corpor introduc d825 1962 fourprocessor comput access 16 memori modul crossbar switch 59 1967 amdahl slotnick publish debat feasibl parallel process american feder inform process societi confer 58 debat amdahl law coin defin limit speedup due parallel 1969 honeywel introduc first multic system symmetr multiprocessor system capabl run eight processor parallel 58 cmmp multiprocessor project carnegi mellon univers 1970 among first multiprocessor processor first busconnect multiprocessor snoop cach synaps n1 1984 55 simd parallel comput trace back 1970 motiv behind earli simd comput amort gate delay processor control unit multipl instruct 60 1964 slotnick propos build massiv parallel comput lawrenc livermor nation laboratori 58 design fund us air forc earliest simd parallelcomput effort illiac iv 58 key design fairli high parallel 256processor allow machin work larg dataset would later known vector process howev illiac iv call infam supercomput project onefourth complet took 11year cost almost four time origin estim 53 final readi run first real applic 1976 outperform exist commerci supercomput cray1 edit earli 1970 mit comput scienc artifici intellig laboratori marvin minski seymour papert start develop societi mind theori view biolog brain massiv parallel comput 1986 minski publish societi mind claim mind form mani littl agent mindless 61 theori attempt explain call intellig could product interact nonintellig part minski say biggest sourc idea theori came work tri creat machin use robot arm video camera comput build children block 62 similar model also view biolog brain massiv parallel comput ie brain made constel independ semiindepend agent also describ thoma r blakesle 63 michael gazzaniga 64 65 robert e ornstein 66 ernest hilgard 67 68 michio kaku 69 georg ivanovich gurdjieff 70 neuroclust brain model 71 edit concurr comput scienc content address parallel processor list distribut comput confer list import public concurr parallel distribut comput manycor multi task parallel program model serializ synchron program transput vector process edit edit sechin parallel comput photogrammetri gim intern 1 2016 pp2123 edit listen articl infodl audio file creat revis articl date 20130821 reflect subsequ edit articl audio help spoken articl wikibook book topic distribut system wikivers learn resourc parallel comput instruct video caf fortran standard john reid see appendix b parallel comput curli base dmoz lawrenc livermor nation laboratori introduct parallel comput design build parallel program ian foster internet parallel comput archiv parallel process topic area ieee distribut comput onlin parallel comput work free onlin book frontier supercomput free onlin book cover topic like algorithm industri applic univers parallel comput research center cours parallel program columbia univers collabor ibm tj watson x10 project parallel distribut grbner base comput ja see also grbner basi cours parallel comput univers wisconsinmadison berkeley par lab progress parallel comput landscap editor david patterson denni gannon michael wrinn august 23 2013 troubl multicor david patterson post 30 jun 2010 landscap parallel comput research view berkeley one mani dead link site introduct parallel comput coursera parallel program v e parallel comput gener distribut comput parallel comput massiv parallel cloud comput highperform comput multiprocess manycor processor gpgpu comput network systol array level bit instruct thread task data memori loop pipelin multithread tempor simultan smt specul spmt preemptiv cooper cluster multithread cmt hardwar scout theori pram model analysi parallel algorithm amdahl law gustafson law cost effici karpflatt metric slowdown speedup element process thread fiber instruct window coordin multiprocess memori coher cach coher cach invalid barrier synchron applic checkpoint program stream process dataflow program model implicit parallel explicit parallel concurr nonblock algorithm hardwar flynn taxonomi sisd simd simt misd mimd dataflow architectur pipelin processor superscalar processor vector processor multiprocessor symmetr asymmetr memori share distribut distribut share uma numa coma massiv parallel comput comput cluster grid comput api ateji px boostthread chapel charm cilk coarray fortran cuda dryad c amp global array mpi openmp opencl openhmpp openacc tpl plinq pvm posix thread raftlib upc tbb zpl problem deadlock livelock determinist algorithm embarrassingli parallel parallel slowdown race condit softwar lockout scalabl starvat categori parallel comput media relat parallel comput wikimedia common retriev httpsenwikipediaorgwindexphptitleparallel_computingoldid840412326 categori parallel comput hidden categori webarch templat wayback link cs1 maint use author paramet spoken articl articl haudio microformat articl curli link featur articl navig menu person tool log talk contribut creat account log namespac view search navig main page content featur content current event random articl donat wikipedia wikipedia store interact help wikipedia commun portal recent chang contact page tool link relat chang upload file special page perman link page inform wikidata item cite page printexport creat book download pdf printabl version project wikimedia common languag azrbaycanca bosanski catal etina deutsch eesti espaol esperanto franai hrvatski bahasa indonesia italiano basa jawa latina latvieu nederland polski portugu romn shqip simpl english slovenina srpski suomi svenska trke ting vit page last edit 9 may 2018 1832 text avail creativ common attributionsharealik licens addit term may appli use site agre term use privaci polici wikipedia regist trademark wikimedia foundat inc nonprofit organ privaci polici wikipedia disclaim contact wikipedia develop cooki statement mobil view 